# `snarfl` :: snarfling all the metadata you need off The Net

`snarfl` = companion tool to `ingest` for gathering metadata "from abroad", e.g.:
  - processing large metadata databases (and their backup/export/import files), such as the sci-hub.ru metadata dump, and produce a "reference library" from those. To be used as search sources where we try to match DOI or title/author with every document in our actual *library* where we are still looking to improve our own metadata set (or rather: get a "reasonable" initial suggest for the metadata for our document X, so that we have a simplified and *faster* job of vetting the metadata gathered ("*snarfled*") through this and other automated processes.
  - roaming the Internet on the prowl for additional metadata opportunities, e.g. automated Google / Bing / DuckDuckGo searches for the title/author and automated decoding/extraction of "initial metadata suggestions": here *versioning*, *version control* and *ranking* / *marking* metadata for each document become important as we MUST be able to tell automated suggestions, automated "finds" in foreign metadata databases and *owner vetted* metadata apart, so that we can report a *reliable* grading/ranking of the same. Given the lousy Google Scholar metadata (my long-time experience with using that) and sometimes dubious quality of other sources' metadata "files", let alone the statistical *uncertainty* inherent in machine-derived/extracted metadata from web + search-engine *scrapes*, a clear and human-grokkable **_ranking per line item_** for any metadata is a **requirement**! Hence we need to equip our tooling (`snarfl`) with the ability to report *source* and *estimated/indicated ranking of said source*, so that the human owner/editor can jump in later and correct/complete/augment any entries she doesn't seem of sufficient quality.
    > *Abstracts* are of particular interest here and prone to the severest modes of "crapping up" when left to automated tools. Here we see a need for both:
    > - *scripting* of particular scraping / extraction processes within `snarfl`.  
    > - *versioning* and *version control*, once again, as we ant to be able to monitor, inspect and report on the (gradual) metadata quality improvement process itself. (ðŸ˜„ðŸ˜‡ *meta* of the *meta*)
    > - later on in this process *human intervention* a.k.a. *editing* will be involved, but that's out of scope for the `snarfl` tool itself as far as I am concerned: what `snarfl` SHOULD provide is the "*departure point*" for this metadata editorial quality improvement process, such that it can commence with the least amount of fuss.

**Thought**: `text-extractor-analyzer`, `hog` and `snarfl` MAY become one and the same tool as these processes, while in different *arenas*[^arenas], probably involve quite a bit of the same *technology* and *type of processes*, so it makes sense to roll these into one "*multitool*".

[^arenas]: The two different *arenas*: text **content** "*snarfing*" & publication **metadata** "*snarfling*"[^snarf]. 

[^snarf]: ðŸ¤¡ Which one will we refer to as *snarfing* (*sans* *elle*)? And which one will be referred to as *snarfling* (*avec du elle*)? The 'l' for "*level up*" (= meta) or the 'l' for *mostly local*? ðŸ¤” Doubting, but when I did *spontaneously write about it just now*, it's apparently the former that's preferred by this individual. ðŸ˜†

